{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "import time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed for ia randomizer\n",
    "ia.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 9 .jpg files\n",
      "ignored 9 other file types\n"
     ]
    }
   ],
   "source": [
    "# fetch certain file types\n",
    "images_names = []\n",
    "ignored = 0\n",
    "\n",
    "for fname in os.listdir('images'):\n",
    "    if fname.endswith('.jpg'):\n",
    "        images_names.append(fname)\n",
    "    else:\n",
    "        ignored += 1\n",
    "\n",
    "print(\"found\", len(images_names), \".jpg files\")\n",
    "print(\"ignored\", ignored, \"other file types\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only bounding box information from .txt file (see format below)\n",
    "def extract_bounding_boxes(file):\n",
    "    bounding_boxes = []\n",
    "    with open(file) as f:\n",
    "        boxes = f.readlines()\n",
    "        for box in boxes:\n",
    "            box_arr = box.split(' ')\n",
    "            bounding_boxes.append(\n",
    "                [box_arr[1], box_arr[2], box_arr[3], box_arr[4].strip(\"\\n\")])\n",
    "    return bounding_boxes\n",
    "\n",
    "# extract only the classification label from .txt file (see format below)\n",
    "\n",
    "\n",
    "def extract_classification_labels(file):\n",
    "    class_labels = []\n",
    "    with open(file) as f:\n",
    "        labels = f.readlines()\n",
    "        for label in labels:\n",
    "            lab_arr = label.split(' ')\n",
    "            class_labels.append(lab_arr[0])\n",
    "    return class_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bounding box .txt files should look as follows:\n",
    "\n",
    "3 0.297656 0.615278 0.118750 0.205556   \n",
    "3 0.622656 0.374306 0.056250 0.093056\n",
    "\n",
    "Where the first number represents a classification label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images found with bounding box(es): 9\n",
      "classifications found for boxes: 9\n",
      "[['0'], ['3'], ['3', '3'], ['3', '0'], ['3'], ['0'], ['0'], ['3', '3'], ['3', '3', '3', '3', '3']]\n"
     ]
    }
   ],
   "source": [
    "# put images in np-array from memory & put corresponding bounding boxes in array in order\n",
    "# bounding_box_images contains tuples in which the first element corresponds to the image and the second element corresponds to the bounding boxes details as an array\n",
    "bounding_box_images = []\n",
    "classification_labels = []\n",
    "\n",
    "for image_name in images_names:\n",
    "    # obtain image\n",
    "    location = \"images/\"+image_name\n",
    "    image = cv2.imread(location)\n",
    "\n",
    "    # obtain bounding boxes\n",
    "    loc = os.path.splitext(location)[0] + '.txt'\n",
    "    bounding_boxes = extract_bounding_boxes(loc)\n",
    "\n",
    "    # put data in tuple and append to array\n",
    "    bounding_box_images.append((image, bounding_boxes))\n",
    "\n",
    "    # save classification labels for future use\n",
    "    classification_labels.append(extract_classification_labels(loc))\n",
    "\n",
    "\n",
    "print(\"images found with bounding box(es):\", len(bounding_box_images))\n",
    "print(\"classifications found for boxes:\", len(classification_labels))\n",
    "print(classification_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert bounding box of format [x1, y1, x2, y2] to yolo box of format [X, Y, W, H]\n",
    "def bbox2yolobox(img_shape, box):\n",
    "    box = [box.x1, box.y1, box.x2, box.y2]\n",
    "    dw = 1./img_shape[1]\n",
    "    dh = 1./img_shape[0]\n",
    "    x = (box[0] + box[2])/2.0\n",
    "    y = (box[1] + box[3])/2.0\n",
    "    w = box[2] - box[0]\n",
    "    h = box[3] - box[1]\n",
    "    x = round(x*dw, 6)\n",
    "    w = round(w*dw, 6)\n",
    "    y = round(y*dh, 6)\n",
    "    h = round(h*dh, 6)\n",
    "    return [x,y,w,h]\n",
    "\n",
    "# convert yolo box of format[X, Y, W, H] to bounding box of format [x1, y1, x2, y2]\n",
    "def yolobbox2bbox(img_shape, box):\n",
    "    height = img_shape[0]\n",
    "    width = img_shape[1]\n",
    "    box = [float(val) for val in box]\n",
    "    x = box[0]\n",
    "    y = box[1]\n",
    "    w = box[2]\n",
    "    h = box[3]\n",
    "    x1, y1 = round((x-w/2)*width, 6), round((y-h/2)*height,6)\n",
    "    x2, y2 = round((x+w/2)*width, 6), round((y+h/2)*height, 6)\n",
    "    \n",
    "    return [x1, y1, x2, y2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented_bb_images folder path\n",
    "path = 'augmented_bb_images/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted augmented_bb_images folder...\n"
     ]
    }
   ],
   "source": [
    "# ONLY EXECUTE THIS CELL BLOCK IF YOU WANT THE CURRENT AUGMENTED IMAGES FOLDER TO BE DELETED!!!\n",
    "\n",
    "# empty augmented_images folder\n",
    "if( input(\"Do you want to delete the current augmented_bb_images folder? (y/n)\").lower() == \"y\"):\n",
    "    for f in os.listdir(path):\n",
    "        os.remove(os.path.join(path, f))\n",
    "    print(\"deleted augmented_bb_images folder...\")\n",
    "else:\n",
    "    print(\"appending new data to existing folder...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, identifier):\n",
    "    for idx, images in enumerate(data):\n",
    "\n",
    "        # save augmented image\n",
    "    \n",
    "        name =  f\"AUG-{identifier}-\" + images_names[idx] \n",
    "        \n",
    "        cv2.imwrite(os.path.join(path, name), images[0]) \n",
    "\n",
    "        # save bounding boxes in yolo format to .txt file\n",
    "        boxes = images[1]\n",
    "        name =  path + f\"AUG-{identifier}-\" + os.path.splitext(images_names[idx])[0] + '.txt'\n",
    "\n",
    "        f = open(name, 'w+')\n",
    "        \n",
    "        for idx2, box in enumerate(boxes):\n",
    "            # print(augmented_bb_images[idx][1])\n",
    "            box_string = \"\"\n",
    "            for item in box:\n",
    "                box_string += str(item) + \" \"\n",
    "            box_string += \"\\n\"\n",
    "            try:\n",
    "                f.write(box_string)\n",
    "            except Exception as ex:\n",
    "                print(\"something went wrong when saving bounding boxes for image:\", name)\n",
    "                print(ex)\n",
    "\n",
    "        f.close()\n",
    "    print(f'saved {identifier} data to {path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(seq):\n",
    "    start = time.time()\n",
    "    # perform image & bounding box augmentation on all images\n",
    "    augmented_bb_images = []\n",
    "    for bb_img in bounding_box_images:\n",
    "\n",
    "        # convert yolo format to bounding box format\n",
    "        bbs_formatted = [yolobbox2bbox(bb_img[0].shape, bb) for bb in bb_img[1]]\n",
    "\n",
    "        # define bbs as required for the imgaug library (BoundingBoxesOnImage type)\n",
    "        bbs = BoundingBoxesOnImage([\n",
    "            BoundingBox(x1=float(bb[0]), y1=float(bb[1]), x2=float(bb[2]), y2=float(bb[3])) for bb in bbs_formatted\n",
    "        ], shape=bb_img[0].shape)\n",
    "\n",
    "        # Augment BBs and images.\n",
    "        aug_img, aug_bbs = seq(image=bb_img[0], bounding_boxes=bbs)\n",
    "\n",
    "        # convert augmented bounding boxes to yolo format\n",
    "        aug_bbs = [bbox2yolobox(bb_img[0].shape, bb)\n",
    "                for bb in aug_bbs.bounding_boxes]\n",
    "\n",
    "        # place augmented image with corresponding augmented boxes in array\n",
    "        aug_bb_img = [aug_img, aug_bbs]\n",
    "\n",
    "        # append array to all augmented data\n",
    "        augmented_bb_images.append(aug_bb_img)\n",
    "\n",
    "    # success log with elapsed time\n",
    "    end = time.time()\n",
    "    elapsed = round((end-start),3)\n",
    "    print(f'succesfully augmented {len(augmented_bb_images)} images with bounding boxes in {elapsed} sec')\n",
    "\n",
    "    # add classification label to each box (necessary for yolo format)\n",
    "    for idx, images in enumerate(augmented_bb_images):\n",
    "        for idx2, box in enumerate(images[1]):\n",
    "            label = classification_labels[idx][idx2]\n",
    "            label_box = [label]\n",
    "            for b in box:\n",
    "                label_box.append(b)\n",
    "            augmented_bb_images[idx][1][idx2] = label_box\n",
    "            \n",
    "    return augmented_bb_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential operations\n",
    "\n",
    "# vertical flip\n",
    "seq_vertical = iaa.Sequential([\n",
    "    iaa.Flipud(1)\n",
    "])\n",
    "\n",
    "# horizontal flip\n",
    "seq_horizontal = iaa.Sequential([\n",
    "    iaa.Fliplr(1)\n",
    "])\n",
    "\n",
    "# vertical & horizontal flip\n",
    "seq_vert_hor = iaa.Sequential([\n",
    "    iaa.Flipud(1),\n",
    "    iaa.Fliplr(1)\n",
    "])\n",
    "\n",
    "# positive saturation (2x multiplier)\n",
    "seq_saturate = iaa.Sequential([\n",
    "    iaa.MultiplySaturation(2, 2)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succesfully augmented 9 images with bounding boxes in 0.006 sec\n",
      "saved VERTICAL data to augmented_bb_images/\n",
      "succesfully augmented 9 images with bounding boxes in 0.015 sec\n",
      "saved HORIZONTAL data to augmented_bb_images/\n",
      "succesfully augmented 9 images with bounding boxes in 0.037 sec\n",
      "saved VERTICAL_HORIZONTAL data to augmented_bb_images/\n"
     ]
    }
   ],
   "source": [
    "# augmentation 1\n",
    "aug1 = augment(seq_vertical)\n",
    "save_data(aug1, \"VERTICAL\")\n",
    "\n",
    "# augmentation 2\n",
    "aug2 = augment(seq_horizontal)\n",
    "save_data(aug2, \"HORIZONTAL\")\n",
    "\n",
    "# augmentation 3\n",
    "aug3 = augment(seq_vert_hor)\n",
    "save_data(aug3, \"VERTICAL_HORIZONTAL\")\n",
    "\n",
    "# augmentation 4\n",
    "# aug4 = augment(seq_saturate)\n",
    "# save_data(aug4, \"SATURATED\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a535705fb941f7f376fd97205253b1f9cc58cca1c08568d5fd0c417c083000d4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('imgaug_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
