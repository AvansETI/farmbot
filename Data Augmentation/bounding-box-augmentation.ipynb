{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed for ia randomizer\n",
    "ia.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 9 .jpg files\n",
      "ignored 9 other file types\n"
     ]
    }
   ],
   "source": [
    "# fetch certain file types\n",
    "images_names = []\n",
    "ignored = 0\n",
    "\n",
    "for fname in os.listdir('images'):\n",
    "    if fname.endswith('.jpg'):\n",
    "        images_names.append(fname)\n",
    "    else:\n",
    "        ignored += 1\n",
    "\n",
    "print(\"found\", len(images_names), \".jpg files\")\n",
    "print(\"ignored\", ignored, \"other file types\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only bounding box information from .txt file (see format below)\n",
    "def extract_bounding_boxes(file):\n",
    "    bounding_boxes = []\n",
    "    with open(file) as f:\n",
    "        boxes = f.readlines()\n",
    "        for box in boxes:\n",
    "            box_arr = box.split(' ')\n",
    "            bounding_boxes.append(\n",
    "                [box_arr[1], box_arr[2], box_arr[3], box_arr[4].strip(\"\\n\")])\n",
    "    return bounding_boxes\n",
    "\n",
    "# extract only the classification label from .txt file (see format below)\n",
    "\n",
    "\n",
    "def extract_classification_labels(file):\n",
    "    class_labels = []\n",
    "    with open(file) as f:\n",
    "        labels = f.readlines()\n",
    "        for label in labels:\n",
    "            lab_arr = label.split(' ')\n",
    "            class_labels.append(lab_arr[0])\n",
    "    return class_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bounding box .txt files should look as follows:\n",
    "\n",
    "3 0.297656 0.615278 0.118750 0.205556   \n",
    "3 0.622656 0.374306 0.056250 0.093056\n",
    "\n",
    "Where the first number represents a classification label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images found with bounding box(es): 9\n",
      "classifications found for boxes: 9\n",
      "[['3', '3'], ['3', '0'], ['0'], ['3'], ['0'], ['3', '3'], ['3', '3', '3', '3', '3'], ['0'], ['3']]\n"
     ]
    }
   ],
   "source": [
    "# put images in np-array from memory & put corresponding bounding boxes in array in order\n",
    "# bounding_box_images contains tuples in which the first element corresponds to the image and the second element corresponds to the bounding boxes details as an array\n",
    "bounding_box_images = []\n",
    "classification_labels = []\n",
    "\n",
    "for image_name in images_names:\n",
    "    # obtain image\n",
    "    location = \"images/\"+image_name\n",
    "    image = cv2.imread(location)\n",
    "\n",
    "    # obtain bounding boxes\n",
    "    loc = os.path.splitext(location)[0] + '.txt'\n",
    "    bounding_boxes = extract_bounding_boxes(loc)\n",
    "\n",
    "    # put data in tuple and append to array\n",
    "    bounding_box_images.append((image, bounding_boxes))\n",
    "\n",
    "    # save classification labels for future use\n",
    "    classification_labels.append(extract_classification_labels(loc))\n",
    "\n",
    "\n",
    "print(\"images found with bounding box(es):\", len(bounding_box_images))\n",
    "print(\"classifications found for boxes:\", len(classification_labels))\n",
    "print(classification_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential operations\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Multiply((1.2, 1.5)),  # change brightness, doesn't affect BBs\n",
    "    iaa.Affine(\n",
    "        translate_px={\"x\": 40, \"y\": 60},\n",
    "        scale=(0.5, 0.7)\n",
    "    )  # translate by 40/60px on x/y axis, and scale to 50-70%, affects BBs\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment BBs and images.\n",
    "\n",
    "# function takes image with corresponding bounding boxes and performs augmentation on both.\n",
    "def augment_bb_image(img, bbs):\n",
    "    x, y = seq(image=img, bounding_boxes=bbs)\n",
    "    return x, y\n",
    "\n",
    "# transforms pixel data from bounding boxes to normalized yolo values\n",
    "\n",
    "\n",
    "def normalize_bounding_boxes(img_shape, bbs):\n",
    "    width = img_shape[0]\n",
    "    heigth = img_shape[1]\n",
    "    normalized_bbs = []\n",
    "    for bb in bbs:\n",
    "        bb_normalized = [round(bb[0]/width, 6), round(bb[1]/heigth, 6),\n",
    "                         round(bb[2]/width, 6), round(bb[3]/heigth, 6)]\n",
    "        normalized_bbs.append(bb_normalized)\n",
    "    return normalized_bbs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3' '0.339543' '0.136804' '0.339712' '0.137022']\n",
      "['3' '0.339484' '0.136744' '0.34002' '0.136894']\n",
      "['3' '0.489656' '0.184267' '0.490197' '0.184474']\n",
      "['0' '0.489763' '0.184248' '0.490061' '0.184286']\n",
      "['0' '0.392805' '0.153757' '0.393022' '0.153998']\n",
      "['3' '0.447974' '0.171057' '0.448069' '0.171363']\n",
      "['0' '0.469294' '0.177916' '0.46943' '0.178075']\n",
      "['3' '0.328478' '0.133256' '0.328853' '0.133471']\n",
      "['3' '0.32863' '0.13331' '0.329156' '0.133692']\n",
      "['3' '0.448872' '0.171328' '0.448982' '0.171382']\n",
      "['3' '0.448893' '0.171465' '0.448929' '0.171481']\n",
      "['3' '0.448831' '0.171371' '0.449048' '0.171558']\n",
      "['3' '0.449001' '0.171409' '0.449281' '0.17164']\n",
      "['3' '0.448787' '0.171424' '0.448858' '0.171584']\n",
      "['0' '0.322539' '0.131425' '0.322644' '0.131532']\n",
      "['3' '0.363694' '0.144378' '0.363734' '0.144425']\n"
     ]
    }
   ],
   "source": [
    "# perform image & bounding box augmentation on all images\n",
    "augmented_bb_images = []\n",
    "for bb_img in bounding_box_images:\n",
    "    # print(len(bb_img[1]))\n",
    "    # extract bounding boxes per image and create BoundingBox objects from data\n",
    "    bbs = BoundingBoxesOnImage([\n",
    "        BoundingBox(x1=bb[0], y1=bb[1], x2=bb[2], y2=bb[3]) for bb in bb_img[1]\n",
    "    ], shape=bb_img[0].shape)\n",
    "\n",
    "    # augmented_bb_images\n",
    "    aug_img, aug_bbs = augment_bb_image(bb_img[0], bbs)\n",
    "\n",
    "    # normalize bounding boxes to yolo format\n",
    "    aug_bbs = [[bb.x1, bb.y1, bb.x2, bb.y2] for bb in aug_bbs]\n",
    "    aug_bbs = normalize_bounding_boxes(bb_img[0].shape, aug_bbs)\n",
    "    aug_bb_img = [aug_img, aug_bbs]\n",
    "    augmented_bb_images.append(aug_bb_img)\n",
    "\n",
    "\n",
    "# add classification label to each box\n",
    "for idx, images in enumerate(augmented_bb_images):\n",
    "    for idx2, box in enumerate(images[1]):\n",
    "        label = classification_labels[idx][idx2]\n",
    "        augmented_bb_images[idx][1] = np.concatenate((label, box), axis=None)\n",
    "        print(augmented_bb_images[idx][1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented_bb_images folder path\n",
    "path = 'augmented_bb_images/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY EXECUTE THIS CELL BLOCK IF YOU WANT THE CURRENT AUGMENTED IMAGES FOLDER TO BE DELETED!!!\n",
    "\n",
    "# empty augmented_images folder\n",
    "\n",
    "for f in os.listdir(path):\n",
    "    os.remove(os.path.join(path, f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3' '0.339484' '0.136744' '0.34002' '0.136894']\n",
      "Mismatch between array dtype ('<U32') and format specifier ('%.18e')\n",
      "['0' '0.489763' '0.184248' '0.490061' '0.184286']\n",
      "Mismatch between array dtype ('<U32') and format specifier ('%.18e')\n",
      "['0' '0.392805' '0.153757' '0.393022' '0.153998']\n",
      "Mismatch between array dtype ('<U32') and format specifier ('%.18e')\n",
      "['3' '0.447974' '0.171057' '0.448069' '0.171363']\n",
      "Mismatch between array dtype ('<U32') and format specifier ('%.18e')\n",
      "['0' '0.469294' '0.177916' '0.46943' '0.178075']\n",
      "Mismatch between array dtype ('<U32') and format specifier ('%.18e')\n",
      "['3' '0.32863' '0.13331' '0.329156' '0.133692']\n",
      "Mismatch between array dtype ('<U32') and format specifier ('%.18e')\n",
      "['3' '0.448787' '0.171424' '0.448858' '0.171584']\n",
      "Mismatch between array dtype ('<U32') and format specifier ('%.18e')\n",
      "['0' '0.322539' '0.131425' '0.322644' '0.131532']\n",
      "Mismatch between array dtype ('<U32') and format specifier ('%.18e')\n",
      "['3' '0.363694' '0.144378' '0.363734' '0.144425']\n",
      "Mismatch between array dtype ('<U32') and format specifier ('%.18e')\n"
     ]
    }
   ],
   "source": [
    "# save augmented images & corresponding bounding boxes in the 'augmented_bb_images' folder\n",
    "\n",
    "for index, img in enumerate(augmented_bb_images):\n",
    "\n",
    "    try:\n",
    "        # save augmented image\n",
    "        name = path+images_names[index]\n",
    "        cv2.imwrite(os.path.join(path, name), img[0])\n",
    "\n",
    "        # save augmented bounding box\n",
    "        name = path + os.path.splitext(images_names[index])[0] + '.txt'\n",
    "        print(img[1])\n",
    "        np.savetxt(name, img[1])\n",
    "        print(\"succesfully saved image with index:\", str(index))\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "\n",
    "# TODO: FIX DAT .TXT FILES WORDEN OPGESLAGEN MET JUISTE BOXES (MISMATCH ERROR) OOK MEERDERE BOXES PER IMAGE!!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a535705fb941f7f376fd97205253b1f9cc58cca1c08568d5fd0c417c083000d4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('imgaug_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
